# Secrets and API keys
# Required: OpenRouter API key for LLM calls
open_router_key=

# Optional: OpenAI API key (only needed for DALLÂ·E fallback in image generation)
open_ai_key=

# Project paths
# Project root (usually '.')
project_root=.

# Test/output directories
tests_output_dir=tests/tests_output
test_source_1=tests/tests_input

# Model mappings (override as needed)
# text_model_1=google/gemini-2.5-flash
# text_model_2=anthropic/claude-sonnet-4
# text_model_3=mistralai/magistral-medium-2506
# text_model_4=google/gemini-2.5-pro
# text_model_5=anthropic/claude-3.7-sonnet
# text_model_6=deepseek/deepseek-chat-v3-0324
# text_model_7=openai/gpt-4o-2024-11-20
# text_model_8=x-ai/grok-beta

# Runtime configuration
# If your service is not launched from an activated venv, set a direct Python path
# Example (macOS/Linux): PYTHON_PATH=/full/path/to/venv/bin/python
# Example (Windows): PYTHON_PATH=C:\\path\\to\\venv\\Scripts\\python.exe
PYTHON_PATH=

# MCP server debug logging (reduce in production)
MCP_DEBUG=false

# Concurrency limits for MCP server
# Maximum concurrent external tasks (LLM calls + Python execs)
MAX_CONCURRENT_TASKS=2
# Requests per second to OpenRouter
OPENROUTER_RPS=2

# Safety flags
# Require explicit opt-in to allow any git commits from automated scripts
ALLOW_GIT_COMMIT=false
